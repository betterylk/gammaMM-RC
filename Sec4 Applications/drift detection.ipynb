{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:35:43.307182Z",
     "start_time": "2024-11-25T01:35:43.234310Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score, recall_score\n",
    "from datetime import timedelta, datetime\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"                # show multi variables without print\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import gamma\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:35:43.626776Z",
     "start_time": "2024-11-25T01:35:43.532167Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_gamma_pdfs(x, params):         # pdf of mixture model\n",
    "    # x: a list of samples, for example, x=[1,2,3,4]\n",
    "    # params: mixing, shape and scale of gamma mix, for example, [[1,0.1,0.2]]\n",
    "    y = np.zeros(len(x))    \n",
    "    for t in np.arange(len(params)):\n",
    "        mixing, alpha, beta = params[t]\n",
    "        temp_y = mixing * stats.gamma.pdf(x, alpha, loc=0, scale=beta)\n",
    "        y = y + temp_y\n",
    "    return y\n",
    " \n",
    "def get_gamma_cdfs(x, params):       # cdf of mixture model\n",
    "    y = np.zeros(len(x))    \n",
    "    for t in np.arange(len(params)):\n",
    "        mixing, alpha, beta = params[t]\n",
    "        temp_y = mixing * stats.gamma.cdf(x, alpha, loc=0, scale=beta)\n",
    "        y = y + temp_y\n",
    "    return y\n",
    "\n",
    "def get_gamma_cdfs_single(x, params):    # cdf of gamma\n",
    "    y = 0\n",
    "    for t in np.arange(len(params)):\n",
    "        mixing, alpha, beta = params[t]\n",
    "        temp_y = mixing * stats.gamma.cdf(x, alpha, loc=0, scale=beta)\n",
    "        y = y + temp_y\n",
    "    return y\n",
    "\n",
    "def get_gamma_ppfs(q, params):    # ppf of mixture model\n",
    "    y = []\n",
    "    \n",
    "    for p in q:\n",
    "        def cdf_minus_p(x):\n",
    "            return get_gamma_cdfs_single(x, params) - p\n",
    "\n",
    "        x_min, x_max = 0, 6\n",
    "        while get_gamma_cdfs_single(x_max, params) < p:\n",
    "            x_max *= 2\n",
    "        y.append(brentq(cdf_minus_p, x_min, x_max))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:35:45.061283Z",
     "start_time": "2024-11-25T01:35:44.977918Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(x, y, data_hist, tag, path_save):\n",
    "    font = {'weight':\"bold\",'size':12}\n",
    "    fontsize = 12\n",
    "    font_legend = {'size':10}\n",
    "    DPI = 300\n",
    "    nbins = 50\n",
    "    colour_names = ['b', 'r', 'c', 'k', 'm']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.6))\n",
    "    ploot = plt.xlim([0,100])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    if tag == 'PDF':\n",
    "        ploot = plt.plot(x, y)\n",
    "        ploot = plt.hist(data_hist, bins=nbins, density=True)\n",
    "    if tag == 'CP':\n",
    "        K = y.shape[1]\n",
    "        for k in np.arange(K): \n",
    "            ploot = plt.plot(x, y[:,k].reshape(-1,1), color=colour_names[k], linestyle='-', label='gamma' + str(k+1))  \n",
    "          \n",
    "        ploot = plt.legend(prop=font_legend)\n",
    "    my_x_ticks = ax.get_xticks()\n",
    "    my_y_ticks = ax.get_yticks()\n",
    "    my_x_ticks = np.round(my_x_ticks, decimals=3)\n",
    "    my_y_ticks = np.round(my_y_ticks, decimals=3)\n",
    "    ploot = ax.set_xticks(my_x_ticks)\n",
    "    ploot = ax.set_xticklabels(my_x_ticks, fontdict=font)\n",
    "    ploot = ax.set_yticks(my_y_ticks)\n",
    "    ploot = ax.set_yticklabels(my_y_ticks, fontdict=font)\n",
    "    \n",
    "    ploot = plt.savefig(path_save, dpi = DPI, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two comparing windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T01:36:09.512010Z",
     "start_time": "2024-11-25T01:36:09.378348Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Sec3 Model fitting/out3Years2/long run/2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6100c70c5068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mK1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath_model\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shape'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scale'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mparameters2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Sec3 Model fitting/out3Years2/long run/2.csv'"
     ]
    }
   ],
   "source": [
    "# Drift detection using KS\n",
    "Path_model = '../Sec3 Model fitting/out3Years2/long run/'\n",
    "path_out = 'OfflineDrift/'\n",
    "# IDs = ['2013', '2014', '2015']\n",
    "IDs = [1,2,3] \n",
    "Nsamples = 200\n",
    "\n",
    "out = []\n",
    "for ID1, ID2 in zip(IDs[0:-1], IDs[1:]):\n",
    "    model1 = pd.read_csv(Path_model + str(ID1) + '/W1.csv')\n",
    "    model1['mean'] = model1['shape'] * model1['scale']\n",
    "    parameters1 = model1.sort_values(by=['mean'], ascending=True).values\n",
    "    parameters1 = parameters1[:,0:3]\n",
    "    K1 = len(parameters1)\n",
    "    \n",
    "    model2 = pd.read_csv(Path_model + str(ID2) + '/W1.csv')\n",
    "    model2['mean'] = model2['shape'] * model2['scale']\n",
    "    parameters2 = model2.sort_values(by=['mean'], ascending=True).values\n",
    "    parameters2 = parameters2[:,0:3]\n",
    "    K2 = len(parameters2)\n",
    "\n",
    "    # sampling data from mixture models\n",
    "    uniform_samples = np.random.uniform(0,1,Nsamples)\n",
    "    samples1 = get_gamma_ppfs(uniform_samples, parameters1)   \n",
    "    samples2 = get_gamma_ppfs(uniform_samples, parameters2)  \n",
    "\n",
    "    t2 = np.linspace(0,1,Nsamples)[1:-1]\n",
    "    samples1_new = get_gamma_ppfs(t2, parameters1)\n",
    "    samples2_new = get_gamma_ppfs(t2, parameters2)\n",
    "\n",
    "    # drift detection\n",
    "    test_statistic, p_KS = stats.ks_2samp(samples1, samples2)\n",
    "    test_statistic = str(np.round(test_statistic,decimals=2))\n",
    "    if 'e' in str(p_KS):\n",
    "        p_KS = str(np.round(float(str(p_KS).split('e')[0]),decimals=2)) + 'e' + str(p_KS).split('e')[1]\n",
    "    else:\n",
    "        p_KS = str(np.round(p_KS,decimals=2))\n",
    "    \n",
    "    # drift rationalization\n",
    "    K1 = model1.values.shape[0]\n",
    "    K2 = model2.values.shape[0]\n",
    "    \n",
    "    if stats.ks_2samp(samples1, samples2)[1] > 0.05:\n",
    "        Dtype = 0\n",
    "    else:\n",
    "        if K1 != K2:    \n",
    "            Dtype = 1\n",
    "        else:\n",
    "            ft1, ft2 = [], []\n",
    "            for k in np.arange(K1):\n",
    "                ft1.append( gamma.pdf(samples1_new, parameters1[k][1], loc=0, scale=parameters1[k][2]) )\n",
    "                ft2.append( gamma.pdf(samples2_new, parameters2[k][1], loc=0, scale=parameters2[k][2]) )\n",
    "            ft1 = np.array(ft1)\n",
    "            ft2 = np.array(ft2)\n",
    "            mixft1 = np.sum(ft1 * parameters1[:,0].reshape(-1,1), axis=0)   \n",
    "            mixft2 = np.sum(ft2 * parameters2[:,0].reshape(-1,1), axis=0)   \n",
    "\n",
    "            isType2 = False\n",
    "            Cprob1, Cprob2 = [], []\n",
    "            uuu = []\n",
    "            yyy = []\n",
    "            for k in np.arange(K1):\n",
    "                con_prob1 = parameters1[k][0] * ft1[k] / mixft1\n",
    "                con_prob2 = parameters2[k][0] * ft2[k] / mixft2\n",
    "                Cprob1.append(con_prob1)\n",
    "                Cprob2.append(con_prob2)\n",
    "\n",
    "#                 _, p_KS2 = stats.ks_2samp(con_prob1, con_prob2)\n",
    "                _, p_KS2 = stats.ttest_rel(con_prob1, con_prob2)\n",
    "#                 _, p_KS2 = stats.wilcoxon(con_prob1, con_prob2)\n",
    "                uuu.append(p_KS2)\n",
    "#                 uuu[0] = uuu[0] * 2\n",
    "                if p_KS2 < 0.05:\n",
    "                    yyy.append(k)\n",
    "                    isType2 = True\n",
    "            if isType2:\n",
    "#                 main_changes = np.argmin(uuu)\n",
    "#                 uuu, main_changes\n",
    "#                 Dtype = '2_' + str(main_changes+1)\n",
    "                Dtype = ', '.join(map(str, yyy))\n",
    "            if isType2 != True:\n",
    "                Dtype = 3       \n",
    "\n",
    "            Cprob1 = np.array(Cprob1).T            \n",
    "            Cprob2 = np.array(Cprob2).T \n",
    "            \n",
    "#             save_fig(t, get_gamma_pdfs(t, parameters1), samples1, 'PDF', 'OfflineDrift/' str(ID1) + '.png')\n",
    "#             save_fig(samples1_new, Cprob1, samples2, 'CP', 'OfflineDrift/' + str(ID1) + '_cp.png') \n",
    "\n",
    "#             save_fig(t, get_gamma_pdfs(t, parameters2), samples2, 'PDF', 'OfflineDrift/' + i.split('.')[0] + '.png')\n",
    "#             if K1 == K2:\n",
    "#                 save_fig(samples1_new, Cprob2, samples2, 'CP', 'OfflineDrift/' + i.split('.')[0] + '_cp.png') \n",
    "                \n",
    "    out.append([ID1, ID2, test_statistic, p_KS, Dtype])\n",
    "df = pd.DataFrame( np.array(out), columns=['ID1', 'ID2', 'statis', 'pvalue', 'Dtype'] )\n",
    "df.to_csv(path_out + 'RC_3years.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
